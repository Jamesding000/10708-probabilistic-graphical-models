{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a4b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import digamma\n",
    "from utils import *\n",
    "from LDA import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f9905",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = \"data/nyt_vocab.txt\"\n",
    "data_path = \"data/nyt_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe1649",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = load_vocab(vocab_path)\n",
    "V = len(vocab)\n",
    "docs_counts = load_nyt_counts(data_path)\n",
    "words = build_corpus_tokens(docs_counts, N=200, min_len=150, seed=0)  # [M, N]\n",
    "np.save(\"outputs/words.npy\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1327c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EM iter 0 ===\n",
      "[E-step] iter=00 avg-delta=3.569e-02\n",
      "[E-step] iter=05 avg-delta=2.695e-02\n",
      "[E-step] iter=10 avg-delta=3.144e-02\n",
      "[E-step] iter=15 avg-delta=3.055e-02\n",
      "[E-step] iter=20 avg-delta=2.462e-02\n",
      "[E-step] iter=25 avg-delta=1.835e-02\n",
      "[E-step] iter=30 avg-delta=1.370e-02\n",
      "[E-step] iter=35 avg-delta=1.061e-02\n",
      "[E-step] converged at iter=37 (avg-delta=9.676e-03)\n",
      "[M-step α] iter=00 ||Δα||=3.067e-02 α_mean=0.103\n",
      "[M-step α] iter=05 ||Δα||=2.234e-03 α_mean=0.109\n",
      "[M-step α] iter=10 ||Δα||=1.140e-04 α_mean=0.109\n",
      "[M-step α] converged at iter=11 (||Δα||=6.327e-05)\n",
      "\n",
      "=== EM iter 1 ===\n",
      "[E-step] iter=00 avg-delta=3.958e-02\n",
      "[E-step] iter=05 avg-delta=2.239e-02\n",
      "[E-step] iter=10 avg-delta=1.558e-02\n",
      "[E-step] iter=15 avg-delta=1.143e-02\n",
      "[E-step] converged at iter=18 (avg-delta=9.721e-03)\n",
      "[M-step α] iter=00 ||Δα||=2.854e-02 α_mean=0.104\n",
      "[M-step α] iter=05 ||Δα||=1.120e-03 α_mean=0.0986\n",
      "[M-step α] iter=10 ||Δα||=6.197e-05 α_mean=0.0983\n",
      "[M-step α] converged at iter=10 (||Δα||=6.197e-05)\n",
      "\n",
      "=== EM iter 2 ===\n",
      "[E-step] iter=00 avg-delta=5.200e-02\n",
      "[E-step] iter=05 avg-delta=2.312e-02\n",
      "[E-step] iter=10 avg-delta=1.400e-02\n",
      "[E-step] iter=15 avg-delta=9.549e-03\n",
      "[E-step] converged at iter=15 (avg-delta=9.549e-03)\n",
      "[M-step α] iter=00 ||Δα||=3.593e-02 α_mean=0.0912\n",
      "[M-step α] iter=05 ||Δα||=1.288e-03 α_mean=0.0847\n",
      "[M-step α] iter=10 ||Δα||=6.693e-05 α_mean=0.0844\n",
      "[M-step α] converged at iter=10 (||Δα||=6.693e-05)\n",
      "\n",
      "=== EM iter 3 ===\n",
      "[E-step] iter=00 avg-delta=4.556e-02\n",
      "[E-step] iter=05 avg-delta=1.684e-02\n",
      "[E-step] iter=10 avg-delta=9.601e-03\n",
      "[E-step] converged at iter=10 (avg-delta=9.601e-03)\n",
      "[M-step α] iter=00 ||Δα||=3.054e-02 α_mean=0.0784\n",
      "[M-step α] iter=05 ||Δα||=1.042e-03 α_mean=0.0731\n",
      "[M-step α] converged at iter=9 (||Δα||=9.369e-05)\n",
      "\n",
      "=== EM iter 4 ===\n",
      "[E-step] iter=00 avg-delta=3.777e-02\n",
      "[E-step] iter=05 avg-delta=1.294e-02\n",
      "[E-step] converged at iter=7 (avg-delta=9.864e-03)\n",
      "[M-step α] iter=00 ||Δα||=2.351e-02 α_mean=0.0682\n",
      "[M-step α] iter=05 ||Δα||=8.006e-04 α_mean=0.0641\n",
      "[M-step α] converged at iter=9 (||Δα||=6.990e-05)\n",
      "\n",
      "=== EM iter 5 ===\n",
      "[E-step] iter=00 avg-delta=3.271e-02\n",
      "[E-step] iter=05 avg-delta=1.085e-02\n",
      "[E-step] converged at iter=6 (avg-delta=9.378e-03)\n",
      "[M-step α] iter=00 ||Δα||=1.821e-02 α_mean=0.0603\n",
      "[M-step α] iter=05 ||Δα||=6.247e-04 α_mean=0.0571\n",
      "[M-step α] converged at iter=8 (||Δα||=9.843e-05)\n",
      "\n",
      "=== EM iter 6 ===\n",
      "[E-step] iter=00 avg-delta=2.858e-02\n",
      "[E-step] iter=05 avg-delta=9.452e-03\n",
      "[E-step] converged at iter=5 (avg-delta=9.452e-03)\n",
      "[M-step α] iter=00 ||Δα||=1.430e-02 α_mean=0.0541\n",
      "[M-step α] iter=05 ||Δα||=4.960e-04 α_mean=0.0515\n",
      "[M-step α] converged at iter=8 (||Δα||=7.715e-05)\n",
      "\n",
      "=== EM iter 7 ===\n",
      "[E-step] iter=00 avg-delta=2.540e-02\n",
      "[E-step] converged at iter=4 (avg-delta=9.950e-03)\n",
      "[M-step α] iter=00 ||Δα||=1.139e-02 α_mean=0.0492\n",
      "[M-step α] iter=05 ||Δα||=3.996e-04 α_mean=0.047\n",
      "[M-step α] converged at iter=8 (||Δα||=6.152e-05)\n",
      "\n",
      "=== EM iter 8 ===\n",
      "[E-step] iter=00 avg-delta=2.293e-02\n",
      "[E-step] converged at iter=4 (avg-delta=9.151e-03)\n",
      "[M-step α] iter=00 ||Δα||=9.294e-03 α_mean=0.0451\n",
      "[M-step α] iter=05 ||Δα||=3.293e-04 α_mean=0.0434\n",
      "[M-step α] converged at iter=7 (||Δα||=9.396e-05)\n",
      "\n",
      "=== EM iter 9 ===\n",
      "[E-step] iter=00 avg-delta=2.023e-02\n",
      "[E-step] converged at iter=3 (avg-delta=9.681e-03)\n",
      "[M-step α] iter=00 ||Δα||=7.702e-03 α_mean=0.0418\n",
      "[M-step α] iter=05 ||Δα||=2.754e-04 α_mean=0.0403\n",
      "[M-step α] converged at iter=7 (||Δα||=7.823e-05)\n",
      "\n",
      "=== EM iter 10 ===\n",
      "[E-step] iter=00 avg-delta=1.849e-02\n",
      "[E-step] converged at iter=3 (avg-delta=9.030e-03)\n",
      "[M-step α] iter=00 ||Δα||=6.508e-03 α_mean=0.039\n",
      "[M-step α] iter=05 ||Δα||=2.344e-04 α_mean=0.0378\n",
      "[M-step α] converged at iter=7 (||Δα||=6.633e-05)\n",
      "\n",
      "=== EM iter 11 ===\n",
      "[E-step] iter=00 avg-delta=1.657e-02\n",
      "[E-step] converged at iter=2 (avg-delta=9.870e-03)\n",
      "[M-step α] iter=00 ||Δα||=5.482e-03 α_mean=0.0366\n",
      "[M-step α] iter=05 ||Δα||=1.992e-04 α_mean=0.0356\n",
      "[M-step α] converged at iter=7 (||Δα||=5.620e-05)\n",
      "\n",
      "=== EM iter 12 ===\n",
      "[E-step] iter=00 avg-delta=1.567e-02\n",
      "[E-step] converged at iter=2 (avg-delta=9.523e-03)\n",
      "[M-step α] iter=00 ||Δα||=4.704e-03 α_mean=0.0346\n",
      "[M-step α] iter=05 ||Δα||=1.720e-04 α_mean=0.0337\n",
      "[M-step α] converged at iter=6 (||Δα||=9.121e-05)\n",
      "\n",
      "=== EM iter 13 ===\n",
      "[E-step] iter=00 avg-delta=1.443e-02\n",
      "[E-step] converged at iter=2 (avg-delta=8.906e-03)\n",
      "[M-step α] iter=00 ||Δα||=4.083e-03 α_mean=0.0329\n",
      "[M-step α] iter=05 ||Δα||=1.502e-04 α_mean=0.0321\n",
      "[M-step α] converged at iter=6 (||Δα||=7.955e-05)\n",
      "\n",
      "=== EM iter 14 ===\n",
      "[E-step] iter=00 avg-delta=1.321e-02\n",
      "[E-step] converged at iter=1 (avg-delta=9.952e-03)\n",
      "[M-step α] iter=00 ||Δα||=3.544e-03 α_mean=0.0314\n",
      "[M-step α] iter=05 ||Δα||=1.312e-04 α_mean=0.0307\n",
      "[M-step α] converged at iter=6 (||Δα||=6.943e-05)\n",
      "\n",
      "=== EM iter 15 ===\n",
      "[E-step] iter=00 avg-delta=1.296e-02\n",
      "[E-step] converged at iter=1 (avg-delta=9.916e-03)\n",
      "[M-step α] iter=00 ||Δα||=3.093e-03 α_mean=0.03\n",
      "[M-step α] iter=05 ||Δα||=1.151e-04 α_mean=0.0294\n",
      "[M-step α] converged at iter=6 (||Δα||=6.087e-05)\n",
      "\n",
      "=== EM iter 16 ===\n",
      "[E-step] iter=00 avg-delta=1.238e-02\n",
      "[E-step] converged at iter=1 (avg-delta=9.563e-03)\n",
      "[M-step α] iter=00 ||Δα||=2.717e-03 α_mean=0.0289\n",
      "[M-step α] iter=05 ||Δα||=1.017e-04 α_mean=0.0283\n",
      "[M-step α] converged at iter=6 (||Δα||=5.374e-05)\n",
      "\n",
      "=== EM iter 17 ===\n",
      "[E-step] iter=00 avg-delta=1.172e-02\n",
      "[E-step] converged at iter=1 (avg-delta=9.119e-03)\n",
      "[M-step α] iter=00 ||Δα||=2.403e-03 α_mean=0.0278\n",
      "[M-step α] iter=05 ||Δα||=9.034e-05 α_mean=0.0274\n",
      "[M-step α] converged at iter=5 (||Δα||=9.034e-05)\n",
      "\n",
      "=== EM iter 18 ===\n",
      "[E-step] iter=00 avg-delta=1.107e-02\n",
      "[E-step] converged at iter=1 (avg-delta=8.651e-03)\n",
      "[M-step α] iter=00 ||Δα||=2.168e-03 α_mean=0.0269\n",
      "[M-step α] iter=05 ||Δα||=8.179e-05 α_mean=0.0265\n",
      "[M-step α] converged at iter=5 (||Δα||=8.179e-05)\n",
      "\n",
      "=== EM iter 19 ===\n",
      "[E-step] iter=00 avg-delta=1.047e-02\n",
      "[E-step] converged at iter=1 (avg-delta=8.211e-03)\n",
      "[M-step α] iter=00 ||Δα||=1.971e-03 α_mean=0.0261\n",
      "[M-step α] iter=05 ||Δα||=7.457e-05 α_mean=0.0257\n",
      "[M-step α] converged at iter=5 (||Δα||=7.457e-05)\n",
      "\n",
      "=== EM iter 20 ===\n",
      "[E-step] iter=00 avg-delta=9.931e-03\n",
      "[E-step] converged at iter=0 (avg-delta=9.931e-03)\n",
      "[M-step α] iter=00 ||Δα||=1.751e-03 α_mean=0.0254\n",
      "[M-step α] iter=05 ||Δα||=6.652e-05 α_mean=0.025\n",
      "[M-step α] converged at iter=5 (||Δα||=6.652e-05)\n",
      "\n",
      "=== EM iter 21 ===\n",
      "[E-step] iter=00 avg-delta=1.025e-02\n",
      "[E-step] converged at iter=1 (avg-delta=8.129e-03)\n",
      "[M-step α] iter=00 ||Δα||=1.621e-03 α_mean=0.0247\n",
      "[M-step α] iter=05 ||Δα||=6.165e-05 α_mean=0.0244\n",
      "[M-step α] converged at iter=5 (||Δα||=6.165e-05)\n",
      "\n",
      "=== EM iter 22 ===\n",
      "[E-step] iter=00 avg-delta=9.384e-03\n",
      "[E-step] converged at iter=0 (avg-delta=9.384e-03)\n",
      "[M-step α] iter=00 ||Δα||=1.450e-03 α_mean=0.0241\n",
      "[M-step α] iter=05 ||Δα||=5.538e-05 α_mean=0.0238\n",
      "[M-step α] converged at iter=5 (||Δα||=5.538e-05)\n",
      "\n",
      "=== EM iter 23 ===\n",
      "[E-step] iter=00 avg-delta=9.539e-03\n",
      "[E-step] converged at iter=0 (avg-delta=9.539e-03)\n",
      "[M-step α] iter=00 ||Δα||=1.309e-03 α_mean=0.0235\n",
      "[M-step α] converged at iter=4 (||Δα||=9.526e-05)\n",
      "\n",
      "=== EM iter 24 ===\n",
      "[E-step] iter=00 avg-delta=9.459e-03\n",
      "[E-step] converged at iter=0 (avg-delta=9.459e-03)\n",
      "[M-step α] iter=00 ||Δα||=1.195e-03 α_mean=0.023\n",
      "[M-step α] converged at iter=4 (||Δα||=8.725e-05)\n",
      "\n",
      "=== EM iter 25 ===\n",
      "[E-step] iter=00 avg-delta=9.282e-03\n",
      "[E-step] converged at iter=0 (avg-delta=9.282e-03)\n",
      "[M-step α] iter=00 ||Δα||=1.098e-03 α_mean=0.0226\n",
      "[M-step α] converged at iter=4 (||Δα||=8.030e-05)\n",
      "\n",
      "=== EM iter 26 ===\n",
      "[E-step] iter=00 avg-delta=9.073e-03\n",
      "[E-step] converged at iter=0 (avg-delta=9.073e-03)\n",
      "[M-step α] iter=00 ||Δα||=1.013e-03 α_mean=0.0222\n",
      "[M-step α] converged at iter=4 (||Δα||=7.425e-05)\n",
      "\n",
      "=== EM iter 27 ===\n",
      "[E-step] iter=00 avg-delta=8.859e-03\n",
      "[E-step] converged at iter=0 (avg-delta=8.859e-03)\n",
      "[M-step α] iter=00 ||Δα||=9.370e-04 α_mean=0.0218\n",
      "[M-step α] converged at iter=4 (||Δα||=6.881e-05)\n",
      "\n",
      "=== EM iter 28 ===\n",
      "[E-step] iter=00 avg-delta=8.643e-03\n",
      "[E-step] converged at iter=0 (avg-delta=8.643e-03)\n",
      "[M-step α] iter=00 ||Δα||=8.706e-04 α_mean=0.0214\n",
      "[M-step α] converged at iter=4 (||Δα||=6.404e-05)\n",
      "\n",
      "=== EM iter 29 ===\n",
      "[E-step] iter=00 avg-delta=8.427e-03\n",
      "[E-step] converged at iter=0 (avg-delta=8.427e-03)\n",
      "[M-step α] iter=00 ||Δα||=8.189e-04 α_mean=0.0211\n",
      "[M-step α] converged at iter=4 (||Δα||=6.033e-05)\n",
      "\n",
      "=== EM iter 30 ===\n",
      "[E-step] iter=00 avg-delta=8.217e-03\n",
      "[E-step] converged at iter=0 (avg-delta=8.217e-03)\n",
      "[M-step α] iter=00 ||Δα||=7.664e-04 α_mean=0.0208\n",
      "[M-step α] converged at iter=4 (||Δα||=5.656e-05)\n",
      "\n",
      "=== EM iter 31 ===\n",
      "[E-step] iter=00 avg-delta=8.015e-03\n",
      "[E-step] converged at iter=0 (avg-delta=8.015e-03)\n",
      "[M-step α] iter=00 ||Δα||=7.172e-04 α_mean=0.0205\n",
      "[M-step α] converged at iter=4 (||Δα||=5.300e-05)\n",
      "\n",
      "=== EM iter 32 ===\n",
      "[E-step] iter=00 avg-delta=7.816e-03\n",
      "[E-step] converged at iter=0 (avg-delta=7.816e-03)\n",
      "[M-step α] iter=00 ||Δα||=6.753e-04 α_mean=0.0202\n",
      "[M-step α] converged at iter=3 (||Δα||=9.512e-05)\n",
      "\n",
      "=== EM iter 33 ===\n",
      "[E-step] iter=00 avg-delta=7.630e-03\n",
      "[E-step] converged at iter=0 (avg-delta=7.630e-03)\n",
      "[M-step α] iter=00 ||Δα||=6.388e-04 α_mean=0.0199\n",
      "[M-step α] converged at iter=3 (||Δα||=9.008e-05)\n",
      "\n",
      "=== EM iter 34 ===\n",
      "[E-step] iter=00 avg-delta=7.460e-03\n",
      "[E-step] converged at iter=0 (avg-delta=7.460e-03)\n",
      "[M-step α] iter=00 ||Δα||=6.027e-04 α_mean=0.0197\n",
      "[M-step α] converged at iter=3 (||Δα||=8.505e-05)\n",
      "\n",
      "=== EM iter 35 ===\n",
      "[E-step] iter=00 avg-delta=7.306e-03\n",
      "[E-step] converged at iter=0 (avg-delta=7.306e-03)\n",
      "[M-step α] iter=00 ||Δα||=5.744e-04 α_mean=0.0195\n",
      "[M-step α] converged at iter=3 (||Δα||=8.110e-05)\n",
      "\n",
      "=== EM iter 36 ===\n",
      "[E-step] iter=00 avg-delta=7.170e-03\n",
      "[E-step] converged at iter=0 (avg-delta=7.170e-03)\n",
      "[M-step α] iter=00 ||Δα||=5.443e-04 α_mean=0.0193\n",
      "[M-step α] converged at iter=3 (||Δα||=7.689e-05)\n",
      "\n",
      "=== EM iter 37 ===\n",
      "[E-step] iter=00 avg-delta=7.047e-03\n",
      "[E-step] converged at iter=0 (avg-delta=7.047e-03)\n",
      "[M-step α] iter=00 ||Δα||=5.179e-04 α_mean=0.0191\n",
      "[M-step α] converged at iter=3 (||Δα||=7.323e-05)\n",
      "\n",
      "=== EM iter 38 ===\n",
      "[E-step] iter=00 avg-delta=6.935e-03\n",
      "[E-step] converged at iter=0 (avg-delta=6.935e-03)\n",
      "[M-step α] iter=00 ||Δα||=4.962e-04 α_mean=0.0189\n",
      "[M-step α] converged at iter=3 (||Δα||=7.020e-05)\n",
      "\n",
      "=== EM iter 39 ===\n",
      "[E-step] iter=00 avg-delta=6.839e-03\n",
      "[E-step] converged at iter=0 (avg-delta=6.839e-03)\n",
      "[M-step α] iter=00 ||Δα||=4.762e-04 α_mean=0.0187\n",
      "[M-step α] converged at iter=3 (||Δα||=6.742e-05)\n",
      "\n",
      "=== EM iter 40 ===\n",
      "[E-step] iter=00 avg-delta=6.763e-03\n",
      "[E-step] converged at iter=0 (avg-delta=6.763e-03)\n",
      "[M-step α] iter=00 ||Δα||=4.521e-04 α_mean=0.0185\n",
      "[M-step α] converged at iter=3 (||Δα||=6.406e-05)\n",
      "\n",
      "=== EM iter 41 ===\n",
      "[E-step] iter=00 avg-delta=6.676e-03\n",
      "[E-step] converged at iter=0 (avg-delta=6.676e-03)\n",
      "[M-step α] iter=00 ||Δα||=4.322e-04 α_mean=0.0183\n",
      "[M-step α] converged at iter=3 (||Δα||=6.129e-05)\n",
      "\n",
      "=== EM iter 42 ===\n",
      "[E-step] iter=00 avg-delta=6.547e-03\n",
      "[E-step] converged at iter=0 (avg-delta=6.547e-03)\n",
      "[M-step α] iter=00 ||Δα||=4.176e-04 α_mean=0.0182\n",
      "[M-step α] converged at iter=3 (||Δα||=5.921e-05)\n",
      "\n",
      "=== EM iter 43 ===\n",
      "[E-step] iter=00 avg-delta=6.405e-03\n",
      "[E-step] converged at iter=0 (avg-delta=6.405e-03)\n",
      "[M-step α] iter=00 ||Δα||=4.014e-04 α_mean=0.018\n",
      "[M-step α] converged at iter=3 (||Δα||=5.692e-05)\n",
      "\n",
      "=== EM iter 44 ===\n",
      "[E-step] iter=00 avg-delta=6.263e-03\n",
      "[E-step] converged at iter=0 (avg-delta=6.263e-03)\n",
      "[M-step α] iter=00 ||Δα||=3.872e-04 α_mean=0.0179\n",
      "[M-step α] converged at iter=3 (||Δα||=5.491e-05)\n",
      "\n",
      "=== EM iter 45 ===\n",
      "[E-step] iter=00 avg-delta=6.116e-03\n",
      "[E-step] converged at iter=0 (avg-delta=6.116e-03)\n",
      "[M-step α] iter=00 ||Δα||=3.775e-04 α_mean=0.0177\n",
      "[M-step α] converged at iter=3 (||Δα||=5.351e-05)\n",
      "\n",
      "=== EM iter 46 ===\n",
      "[E-step] iter=00 avg-delta=5.964e-03\n",
      "[E-step] converged at iter=0 (avg-delta=5.964e-03)\n",
      "[M-step α] iter=00 ||Δα||=3.626e-04 α_mean=0.0176\n",
      "[M-step α] converged at iter=2 (||Δα||=9.820e-05)\n",
      "\n",
      "=== EM iter 47 ===\n",
      "[E-step] iter=00 avg-delta=5.810e-03\n",
      "[E-step] converged at iter=0 (avg-delta=5.810e-03)\n",
      "[M-step α] iter=00 ||Δα||=3.522e-04 α_mean=0.0175\n",
      "[M-step α] converged at iter=2 (||Δα||=9.540e-05)\n",
      "\n",
      "=== EM iter 48 ===\n",
      "[E-step] iter=00 avg-delta=5.660e-03\n",
      "[E-step] converged at iter=0 (avg-delta=5.660e-03)\n",
      "[M-step α] iter=00 ||Δα||=3.412e-04 α_mean=0.0173\n",
      "[M-step α] converged at iter=2 (||Δα||=9.240e-05)\n",
      "\n",
      "=== EM iter 49 ===\n",
      "[E-step] iter=00 avg-delta=5.518e-03\n",
      "[E-step] converged at iter=0 (avg-delta=5.518e-03)\n",
      "[M-step α] iter=00 ||Δα||=3.327e-04 α_mean=0.0172\n",
      "[M-step α] converged at iter=2 (||Δα||=9.012e-05)\n",
      "\n",
      "[fit] Done. Parameters ready: alpha [K], beta [K,V], gamma [M,K].\n"
     ]
    }
   ],
   "source": [
    "# Train LDA model\n",
    "lda = LDA(\n",
    "    K=25, \n",
    "    N=200, \n",
    "    max_em_iters=50, \n",
    "    max_e_iters=100,\n",
    "    tol_e=1e-2,\n",
    "    tol_alpha=1e-4,\n",
    "    seed=0\n",
    ")\n",
    "lda.fit(words, V=len(vocab))\n",
    "lda.save_params(\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb2bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_path=\"outputs/beta.npy\"\n",
    "vocab_path=\"data/nyt_vocab.txt\"\n",
    "num_topics=25\n",
    "top_n=10\n",
    "seed=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d0bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words_for_topic(beta: np.ndarray, vocab: list[str], k: int, top_n: int = 10):\n",
    "    row = beta[k]\n",
    "    idx = np.argpartition(row, -top_n)[-top_n:]\n",
    "    idx = idx[np.argsort(row[idx])[::-1]]\n",
    "    return [(vocab[i], float(row[i])) for i in idx]\n",
    "\n",
    "def sample_topics(K: int, num: int = 5, seed: int = 0) -> np.ndarray:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return np.sort(rng.choice(K, size=num, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6dbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0 (top 10 words):\n",
      "home, open, city, house, area, small, place, lot, start, street\n",
      "\n",
      "Topic 1 (top 10 words):\n",
      "price, company, market, percent, sell, american, food, change, industry, service\n",
      "\n",
      "Topic 2 (top 10 words):\n",
      "political, state, vote, republican, party, leader, support, campaign, election, issue\n",
      "\n",
      "Topic 3 (top 10 words):\n",
      "company, percent, executive, market, industry, chief, analyst, increase, business, stock\n",
      "\n",
      "Topic 4 (top 10 words):\n",
      "official, issue, law, president, question, member, pay, company, case, government\n",
      "\n",
      "Topic 5 (top 10 words):\n",
      "percent, school, program, state, child, problem, student, public, city, pay\n",
      "\n",
      "Topic 6 (top 10 words):\n",
      "company, business, stock, market, executive, sell, buy, deal, large, percent\n",
      "\n",
      "Topic 7 (top 10 words):\n",
      "country, political, military, states, power, american, government, group, official, war\n",
      "\n",
      "Topic 8 (top 10 words):\n",
      "art, life, world, child, woman, play, write, present, open, artist\n",
      "\n",
      "Topic 9 (top 10 words):\n",
      "official, government, political, leader, support, plan, policy, force, state, issue\n",
      "\n",
      "Topic 10 (top 10 words):\n",
      "woman, life, man, child, young, family, father, mother, home, tell\n",
      "\n",
      "Topic 11 (top 10 words):\n",
      "system, thing, change, issue, number, community, area, feel, group, case\n",
      "\n",
      "Topic 12 (top 10 words):\n",
      "case, campaign, hold, state, ask, public, candidate, win, tell, play\n",
      "\n",
      "Topic 13 (top 10 words):\n",
      "company, pay, cost, plan, money, receive, require, program, service, percent\n",
      "\n",
      "Topic 14 (top 10 words):\n",
      "report, case, effect, study, publish, tell, question, cause, life, expert\n",
      "\n",
      "Topic 15 (top 10 words):\n",
      "life, mrs, home, place, thing, add, live, building, house, large\n",
      "\n",
      "Topic 16 (top 10 words):\n",
      "percent, money, plan, cost, market, large, total, pay, project, increase\n",
      "\n",
      "Topic 17 (top 10 words):\n",
      "book, life, man, woman, turn, write, young, great, thing, love\n",
      "\n",
      "Topic 18 (top 10 words):\n",
      "game, play, team, win, player, point, second, victory, season, final\n",
      "\n",
      "Topic 19 (top 10 words):\n",
      "game, play, win, thing, team, season, hit, player, lose, point\n",
      "\n",
      "Topic 20 (top 10 words):\n",
      "states, american, country, official, government, percent, international, market, increase, world\n",
      "\n",
      "Topic 21 (top 10 words):\n",
      "play, film, television, life, art, music, woman, man, performance, movie\n",
      "\n",
      "Topic 22 (top 10 words):\n",
      "report, official, police, force, group, mile, hour, attack, military, spokesman\n",
      "\n",
      "Topic 23 (top 10 words):\n",
      "official, police, case, tell, charge, man, public, report, ask, member\n",
      "\n",
      "Topic 24 (top 10 words):\n",
      "thing, place, life, book, play, turn, world, write, live, man\n"
     ]
    }
   ],
   "source": [
    "beta = np.load(beta_path)\n",
    "vocab = load_vocab(vocab_path)\n",
    "K, V = beta.shape\n",
    "\n",
    "topics = sample_topics(K, num_topics, seed)\n",
    "for k in topics:\n",
    "    words = top_words_for_topic(beta, vocab, k, top_n)\n",
    "    print(f\"\\nTopic {k} (top {top_n} words):\")\n",
    "    print(\", \".join(w for w, _ in words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f406b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_path=\"outputs/beta.npy\"\n",
    "gamma_path=\"outputs/gamma.npy\"\n",
    "vocab_path=\"data/nyt_vocab.txt\"\n",
    "\n",
    "top_topics=3\n",
    "top_words=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9763815f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Document -2 [Music] Pink Floyd Article ===\n",
      "Top topics and their θ weights:\n",
      "  Topic 15: θ=0.9608\n",
      "   Top words: life, mrs, home, place, thing, add, live, building, house, large\n",
      "  Topic 7: θ=0.0372\n",
      "   Top words: country, political, military, states, power, american, government, group, official, war\n",
      "  Topic 20: θ=0.0001\n",
      "   Top words: states, american, country, official, government, percent, international, market, increase, world\n",
      "\n",
      "=== Document -1 [Sport] Lakers Article ===\n",
      "Top topics and their θ weights:\n",
      "  Topic 12: θ=0.5701\n",
      "   Top words: case, campaign, hold, state, ask, public, candidate, win, tell, play\n",
      "  Topic 5: θ=0.3910\n",
      "   Top words: percent, school, program, state, child, problem, student, public, city, pay\n",
      "  Topic 8: θ=0.0371\n",
      "   Top words: art, life, world, child, woman, play, write, present, open, artist\n"
     ]
    }
   ],
   "source": [
    "beta = np.load(beta_path)   # [K, V]\n",
    "gamma = np.load(gamma_path) # [M, K]\n",
    "vocab = load_vocab(vocab_path)\n",
    "\n",
    "theta = gamma / gamma.sum(axis=1, keepdims=True)\n",
    "\n",
    "doc_indices = [-2, -1]\n",
    "names = [\"[Music] Pink Floyd Article\", \"[Sport] Lakers Article\"]\n",
    "\n",
    "for d, name in zip(doc_indices, names):\n",
    "    theta_d = theta[d]\n",
    "    topk = np.argsort(theta_d)[-top_topics:][::-1]\n",
    "    print(f\"\\n=== Document {d} {name} ===\")\n",
    "    for k in topk:\n",
    "        print(f\"  Topic {k}: θ={theta_d[k]:.4f}\")\n",
    "        words = top_words_for_topic(beta, vocab, k, top_words)\n",
    "        print(\"   Top words:\", \", \".join(w for w, _ in words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e70457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_theta(words, alpha, beta, max_iters=50):\n",
    "    M, N = words.shape\n",
    "    K = len(alpha)\n",
    "    phi = np.full((M, N, K), 1.0 / K)\n",
    "    gamma = np.tile(alpha + N / K, (M, 1))\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        dig = digamma(gamma)\n",
    "        beta_lookup = np.zeros((M, N, K))\n",
    "        for k in range(K):\n",
    "            beta_lookup[:, :, k] = beta[k, words]\n",
    "        \n",
    "        phi = beta_lookup * np.exp(dig[:, None, :])\n",
    "        phi /= phi.sum(axis=2, keepdims=True) + 1e-12\n",
    "        gamma = alpha + phi.sum(axis=1)\n",
    "    \n",
    "    return gamma / gamma.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ba604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Document -2 [Music] Pink Floyd Article ===\n",
      "  Topic 24: θ=0.3950\n",
      "   Top words: thing, place, life, book, play, turn, world, write, live, man\n",
      "  Topic 21: θ=0.1964\n",
      "   Top words: play, film, television, life, art, music, woman, man, performance, movie\n",
      "  Topic 8: θ=0.1711\n",
      "   Top words: art, life, world, child, woman, play, write, present, open, artist\n",
      "\n",
      "=== Document -1 [Sport] Lakers Article ===\n",
      "  Topic 18: θ=0.4796\n",
      "   Top words: game, play, team, win, player, point, second, victory, season, final\n",
      "  Topic 19: θ=0.2850\n",
      "   Top words: game, play, win, thing, team, season, hit, player, lose, point\n",
      "  Topic 5: θ=0.0869\n",
      "   Top words: percent, school, program, state, child, problem, student, public, city, pay\n"
     ]
    }
   ],
   "source": [
    "alpha_path = \"outputs/alpha.npy\"\n",
    "beta_path = \"outputs/beta.npy\"\n",
    "data_path = \"data/nyt_data.txt\"\n",
    "vocab_path = \"data/nyt_vocab.txt\"\n",
    "N=200\n",
    "seed=0\n",
    "top_topics=3\n",
    "top_words=10\n",
    "alpha = np.load(alpha_path)\n",
    "beta  = np.load(beta_path)\n",
    "vocab = load_vocab(vocab_path)\n",
    "docs  = load_nyt_counts(data_path)\n",
    "\n",
    "last_two = docs[-2:]\n",
    "rng = np.random.default_rng(seed)\n",
    "sampled = []\n",
    "for pairs in last_two:\n",
    "    toks = expand_counts_to_tokens(pairs)\n",
    "    idx = rng.integers(0, toks.shape[0], size=N) if toks.shape[0] < N else rng.choice(toks.shape[0], size=N, replace=False)\n",
    "    sampled.append(toks[idx])\n",
    "words = np.stack(sampled, 0).astype(np.int32)  # [2,N]\n",
    "\n",
    "theta = infer_theta(words, alpha, beta, max_iters=100, tol=1e-3)\n",
    "\n",
    "names = [\"[Music] Pink Floyd Article\", \"[Sport] Lakers Article\"]\n",
    "for d, name in zip(doc_indices, names):\n",
    "    theta_d = theta[d]\n",
    "    topk = np.argsort(theta_d)[-top_topics:][::-1]\n",
    "    print(f\"\\n=== Document {d} {name} ===\")\n",
    "    for k in topk:\n",
    "        print(f\"  Topic {k}: θ={theta_d[k]:.4f}\")\n",
    "        words = top_words_for_topic(beta, vocab, k, top_words)\n",
    "        print(\"   Top words:\", \", \".join(w for w, _ in words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5c6f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_doc(theta_row, beta, vocab, length=30, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    K, V = beta.shape\n",
    "    topics = rng.choice(K, size=length, p=theta_row)\n",
    "    words = [rng.choice(V, p=beta[t]) for t in topics]\n",
    "    return \" \".join(vocab[w] for w in words), topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199dd223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 30-word doc for [Music] Pink Floyd Article\n",
      "sing tale water step standard allow small star study corporate victory dry murder important colleague minority foot hit aide political return play mention dinner ride tend practice writer live hold\n",
      "Topics: 24(count=16), 8(count=6), 21(count=5)\n",
      "\n",
      "Generated 30-word doc for [Sport] Lakers Article\n",
      "away estimate large goal sure big past college raise final word win ball team guy add measure confidence minute team kind love medium force play contact class ball reject hot\n",
      "Topics: 18(count=13), 19(count=10), 1(count=4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alpha_path=\"outputs/alpha.npy\"\n",
    "beta_path=\"outputs/beta.npy\"\n",
    "data_path=\"data/nyt_data.txt\"\n",
    "vocab_path=\"data/nyt_vocab.txt\"\n",
    "N=200\n",
    "L=30\n",
    "seed=0\n",
    "alpha = np.load(alpha_path) \n",
    "beta  = np.load(beta_path)\n",
    "vocab = load_vocab(vocab_path)\n",
    "\n",
    "docs_raw = load_nyt_counts(data_path)\n",
    "last_two = docs_raw[-2:]\n",
    "rng = np.random.default_rng(seed)\n",
    "sampled = []\n",
    "for pairs in docs[-2:]:\n",
    "    toks = expand_counts_to_tokens(pairs)\n",
    "    sampled.append(sample_document_tokens(toks, 200, rng))\n",
    "words = np.stack(sampled)\n",
    "theta = infer_theta(words, alpha, beta)\n",
    "\n",
    "names = [\"[Music] Pink Floyd Article\", \"[Sport] Lakers Article\"]\n",
    "for i, name in enumerate(names):\n",
    "    gen_text, topics = generate_doc(theta[i], beta, vocab, 30, seed=42+i)\n",
    "    counts = np.bincount(topics, minlength=25)\n",
    "    print(f\"Generated 30-word doc for {name}\")\n",
    "    print(gen_text)\n",
    "    top3 = np.argsort(counts)[-3:][::-1]\n",
    "    print(f\"Topics: {', '.join(f'{t}(count={counts[t]})' for t in top3)}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c2e683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a529616f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
